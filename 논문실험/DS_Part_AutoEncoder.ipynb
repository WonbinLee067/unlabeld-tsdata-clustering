{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = open('resources/InsectWingbeatSound/InsectWingbeatSound_TEST','r')\n",
    "data = f.read()\n",
    "f.close()\n",
    "# 개행문자 기준으로 끊어서 리스트로\n",
    "data_list = data.split('\\n')\n",
    "\n",
    "# \",\" 기준으로 끊어서 리스트로\n",
    "emptylist = []\n",
    "for list_part in data_list:\n",
    "    emptylist.append(list_part.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str -> float 변환\n",
    "tofloat = []\n",
    "for partlist in emptylist:\n",
    "    tofloat.append([float(i) for i in partlist]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980,)\n",
      "(1980, 256)\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "data_list = []\n",
    "for datas in tofloat:\n",
    "    labels.append(datas[0])\n",
    "    data_list.append(datas[1:])\n",
    "print(np.shape(labels))\n",
    "print(np.shape(data_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from readFile import split_into_values, toRPdata\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler\n",
    "\n",
    "def Standard(data):\n",
    "    SS = StandardScaler().fit(data)\n",
    "    scaled = SS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "def MinMax(data):\n",
    "    MMS = MinMaxScaler().fit(data)\n",
    "    scaled = MMS.transform(data)\n",
    "    return scaled\n",
    "\n",
    "# result_list transpose\n",
    "result_T = [list(x) for x in zip(*data_list)]\n",
    "\n",
    "# minmax 정규화\n",
    "result_scaled = Standard(result_T)\n",
    "\n",
    "# 다시 result transpose 해서 원래대로\n",
    "result_scaled = [list(x) for x in zip(*result_scaled)]\n",
    "\n",
    "result_ = np.array(result_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 256, 256, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = result_.reshape(result_.shape[0], 1, result_.shape[1])\n",
    "X = toRPdata(data, threshold='point', percentage=30)\n",
    "#X = toRPdata(data)\n",
    "    \n",
    "X_scaled = np.expand_dims(X, axis=3)\n",
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20ddade5cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer='Adam'\n",
    "loss='binary_crossentropy'\n",
    "image_size = 256 #1024, 256\n",
    "dimension = 16 # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 64)      640       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      18464     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        4624      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 1)         145       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 1)           10        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 256, 1)       577       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256, 256, 1)       0         \n",
      "=================================================================\n",
      "Total params: 47,756\n",
      "Trainable params: 47,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from utils import split_data, normalization_tool\n",
    "from agent import Autoencoder_Agent\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_data(X_scaled, X_scaled) #데이터 분리\n",
    "\n",
    "autoencoder = Autoencoder_Agent(model_size=image_size, dimension=dimension, optimizer=optimizer,learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "149/149 [==============================] - ETA: 0s - loss: 0.6785\n",
      "Epoch 00001: val_loss improved from inf to 0.66448, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 14s 95ms/step - loss: 0.6785 - val_loss: 0.6645\n",
      "Epoch 2/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.6376\n",
      "Epoch 00002: val_loss improved from 0.66448 to 0.60959, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.6376 - val_loss: 0.6096\n",
      "Epoch 3/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5995\n",
      "Epoch 00003: val_loss improved from 0.60959 to 0.59244, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5995 - val_loss: 0.5924\n",
      "Epoch 4/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5935\n",
      "Epoch 00004: val_loss improved from 0.59244 to 0.58995, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5934 - val_loss: 0.5899\n",
      "Epoch 5/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5917\n",
      "Epoch 00005: val_loss improved from 0.58995 to 0.58838, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5917 - val_loss: 0.5884\n",
      "Epoch 6/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5903\n",
      "Epoch 00006: val_loss improved from 0.58838 to 0.58776, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5903 - val_loss: 0.5878\n",
      "Epoch 7/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5891\n",
      "Epoch 00007: val_loss improved from 0.58776 to 0.58629, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5891 - val_loss: 0.5863\n",
      "Epoch 8/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5879\n",
      "Epoch 00008: val_loss improved from 0.58629 to 0.58552, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5880 - val_loss: 0.5855\n",
      "Epoch 9/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5870\n",
      "Epoch 00009: val_loss improved from 0.58552 to 0.58468, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5870 - val_loss: 0.5847\n",
      "Epoch 10/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5861\n",
      "Epoch 00010: val_loss improved from 0.58468 to 0.58396, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5860 - val_loss: 0.5840\n",
      "Epoch 11/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5855\n",
      "Epoch 00011: val_loss improved from 0.58396 to 0.58337, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5853 - val_loss: 0.5834\n",
      "Epoch 12/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5848\n",
      "Epoch 00012: val_loss did not improve from 0.58337\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5848 - val_loss: 0.5834\n",
      "Epoch 13/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5840\n",
      "Epoch 00013: val_loss improved from 0.58337 to 0.58251, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5840 - val_loss: 0.5825\n",
      "Epoch 14/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5835\n",
      "Epoch 00014: val_loss improved from 0.58251 to 0.58205, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5836 - val_loss: 0.5820\n",
      "Epoch 15/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5829\n",
      "Epoch 00015: val_loss improved from 0.58205 to 0.58173, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5830 - val_loss: 0.5817\n",
      "Epoch 16/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5825\n",
      "Epoch 00016: val_loss improved from 0.58173 to 0.58165, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5826 - val_loss: 0.5817\n",
      "Epoch 17/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5819\n",
      "Epoch 00017: val_loss improved from 0.58165 to 0.58079, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5820 - val_loss: 0.5808\n",
      "Epoch 18/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5816\n",
      "Epoch 00018: val_loss improved from 0.58079 to 0.58055, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5817 - val_loss: 0.5806\n",
      "Epoch 19/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5812\n",
      "Epoch 00019: val_loss improved from 0.58055 to 0.58008, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 87ms/step - loss: 0.5812 - val_loss: 0.5801\n",
      "Epoch 20/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5810\n",
      "Epoch 00020: val_loss improved from 0.58008 to 0.57976, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5809 - val_loss: 0.5798\n",
      "Epoch 21/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5805- ETA: 0s - lo\n",
      "Epoch 00021: val_loss improved from 0.57976 to 0.57974, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5805 - val_loss: 0.5797\n",
      "Epoch 22/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5802\n",
      "Epoch 00022: val_loss improved from 0.57974 to 0.57934, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5802 - val_loss: 0.5793\n",
      "Epoch 23/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5798\n",
      "Epoch 00023: val_loss did not improve from 0.57934\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5799 - val_loss: 0.5796\n",
      "Epoch 24/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5796\n",
      "Epoch 00024: val_loss improved from 0.57934 to 0.57905, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5796 - val_loss: 0.5790\n",
      "Epoch 25/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5793\n",
      "Epoch 00025: val_loss improved from 0.57905 to 0.57880, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5793 - val_loss: 0.5788\n",
      "Epoch 26/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5789\n",
      "Epoch 00026: val_loss improved from 0.57880 to 0.57875, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5790 - val_loss: 0.5787\n",
      "Epoch 27/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5787\n",
      "Epoch 00027: val_loss improved from 0.57875 to 0.57861, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5787 - val_loss: 0.5786\n",
      "Epoch 28/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5786\n",
      "Epoch 00028: val_loss did not improve from 0.57861\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5786 - val_loss: 0.5787\n",
      "Epoch 29/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5783\n",
      "Epoch 00029: val_loss improved from 0.57861 to 0.57853, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5784 - val_loss: 0.5785\n",
      "Epoch 30/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5780\n",
      "Epoch 00030: val_loss improved from 0.57853 to 0.57827, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5781 - val_loss: 0.5783\n",
      "Epoch 31/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5779\n",
      "Epoch 00031: val_loss did not improve from 0.57827\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5780 - val_loss: 0.5790\n",
      "Epoch 32/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.5776\n",
      "Epoch 00032: val_loss improved from 0.57827 to 0.57798, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5776 - val_loss: 0.5780\n",
      "Epoch 33/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5775\n",
      "Epoch 00033: val_loss improved from 0.57798 to 0.57784, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 86ms/step - loss: 0.5775 - val_loss: 0.5778\n",
      "Epoch 34/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5774\n",
      "Epoch 00034: val_loss improved from 0.57784 to 0.57757, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5772 - val_loss: 0.5776\n",
      "Epoch 35/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5770\n",
      "Epoch 00035: val_loss did not improve from 0.57757\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5771 - val_loss: 0.5776\n",
      "Epoch 36/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5770\n",
      "Epoch 00036: val_loss improved from 0.57757 to 0.57734, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5770 - val_loss: 0.5773\n",
      "Epoch 37/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5768\n",
      "Epoch 00037: val_loss did not improve from 0.57734\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5767 - val_loss: 0.5776\n",
      "Epoch 38/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5767\n",
      "Epoch 00038: val_loss improved from 0.57734 to 0.57711, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5767 - val_loss: 0.5771\n",
      "Epoch 39/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5763\n",
      "Epoch 00039: val_loss improved from 0.57711 to 0.57707, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5763 - val_loss: 0.5771\n",
      "Epoch 40/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5762\n",
      "Epoch 00040: val_loss improved from 0.57707 to 0.57677, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5762 - val_loss: 0.5768\n",
      "Epoch 41/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5761\n",
      "Epoch 00041: val_loss did not improve from 0.57677\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5760 - val_loss: 0.5771\n",
      "Epoch 42/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5762\n",
      "Epoch 00042: val_loss improved from 0.57677 to 0.57665, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5759 - val_loss: 0.5766\n",
      "Epoch 43/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5755\n",
      "Epoch 00043: val_loss improved from 0.57665 to 0.57654, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5756 - val_loss: 0.5765\n",
      "Epoch 44/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5755\n",
      "Epoch 00044: val_loss improved from 0.57654 to 0.57645, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5755 - val_loss: 0.5764\n",
      "Epoch 45/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5753\n",
      "Epoch 00045: val_loss improved from 0.57645 to 0.57636, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5752 - val_loss: 0.5764\n",
      "Epoch 46/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5753\n",
      "Epoch 00046: val_loss improved from 0.57636 to 0.57613, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5752 - val_loss: 0.5761\n",
      "Epoch 47/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5749\n",
      "Epoch 00047: val_loss improved from 0.57613 to 0.57594, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5749 - val_loss: 0.5759\n",
      "Epoch 48/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5746\n",
      "Epoch 00048: val_loss improved from 0.57594 to 0.57574, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5746 - val_loss: 0.5757\n",
      "Epoch 49/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5743\n",
      "Epoch 00049: val_loss improved from 0.57574 to 0.57564, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5744 - val_loss: 0.5756\n",
      "Epoch 50/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5743\n",
      "Epoch 00050: val_loss did not improve from 0.57564\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5742 - val_loss: 0.5757\n",
      "Epoch 51/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5743\n",
      "Epoch 00051: val_loss did not improve from 0.57564\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5742 - val_loss: 0.5763\n",
      "Epoch 52/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5739\n",
      "Epoch 00052: val_loss improved from 0.57564 to 0.57553, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5739 - val_loss: 0.5755\n",
      "Epoch 53/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5737\n",
      "Epoch 00053: val_loss did not improve from 0.57553\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5737 - val_loss: 0.5756\n",
      "Epoch 54/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5735\n",
      "Epoch 00054: val_loss improved from 0.57553 to 0.57521, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5734 - val_loss: 0.5752\n",
      "Epoch 55/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5731\n",
      "Epoch 00055: val_loss improved from 0.57521 to 0.57506, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5732 - val_loss: 0.5751\n",
      "Epoch 56/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5730\n",
      "Epoch 00056: val_loss did not improve from 0.57506\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5730 - val_loss: 0.5753\n",
      "Epoch 57/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5729\n",
      "Epoch 00057: val_loss improved from 0.57506 to 0.57452, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5728 - val_loss: 0.5745\n",
      "Epoch 58/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5725\n",
      "Epoch 00058: val_loss did not improve from 0.57452\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5726 - val_loss: 0.5749\n",
      "Epoch 59/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5723\n",
      "Epoch 00059: val_loss did not improve from 0.57452\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5723 - val_loss: 0.5745\n",
      "Epoch 60/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5720\n",
      "Epoch 00060: val_loss improved from 0.57452 to 0.57431, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5720 - val_loss: 0.5743\n",
      "Epoch 61/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5717\n",
      "Epoch 00061: val_loss improved from 0.57431 to 0.57403, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5719 - val_loss: 0.5740\n",
      "Epoch 62/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5715\n",
      "Epoch 00062: val_loss improved from 0.57403 to 0.57371, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5716 - val_loss: 0.5737\n",
      "Epoch 63/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5713\n",
      "Epoch 00063: val_loss improved from 0.57371 to 0.57360, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5714 - val_loss: 0.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5713\n",
      "Epoch 00064: val_loss improved from 0.57360 to 0.57354, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5712 - val_loss: 0.5735\n",
      "Epoch 65/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5710\n",
      "Epoch 00065: val_loss improved from 0.57354 to 0.57334, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5708 - val_loss: 0.5733\n",
      "Epoch 66/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5705\n",
      "Epoch 00066: val_loss improved from 0.57334 to 0.57288, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5705 - val_loss: 0.5729\n",
      "Epoch 67/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5702\n",
      "Epoch 00067: val_loss did not improve from 0.57288\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5701 - val_loss: 0.5729\n",
      "Epoch 68/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5700\n",
      "Epoch 00068: val_loss did not improve from 0.57288\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5699 - val_loss: 0.5749\n",
      "Epoch 69/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5697\n",
      "Epoch 00069: val_loss improved from 0.57288 to 0.57224, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5697 - val_loss: 0.5722\n",
      "Epoch 70/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5698\n",
      "Epoch 00070: val_loss improved from 0.57224 to 0.57211, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5697 - val_loss: 0.5721\n",
      "Epoch 71/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5693\n",
      "Epoch 00071: val_loss improved from 0.57211 to 0.57193, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5693 - val_loss: 0.5719\n",
      "Epoch 72/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5690\n",
      "Epoch 00072: val_loss improved from 0.57193 to 0.57175, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5690 - val_loss: 0.5718\n",
      "Epoch 73/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5686\n",
      "Epoch 00073: val_loss did not improve from 0.57175\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5687 - val_loss: 0.5718\n",
      "Epoch 74/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5684\n",
      "Epoch 00074: val_loss did not improve from 0.57175\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5685 - val_loss: 0.5718\n",
      "Epoch 75/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5683\n",
      "Epoch 00075: val_loss improved from 0.57175 to 0.57124, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5682 - val_loss: 0.5712\n",
      "Epoch 76/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5677\n",
      "Epoch 00076: val_loss improved from 0.57124 to 0.57087, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5678 - val_loss: 0.5709\n",
      "Epoch 77/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5678\n",
      "Epoch 00077: val_loss did not improve from 0.57087\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5677 - val_loss: 0.5710\n",
      "Epoch 78/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5675\n",
      "Epoch 00078: val_loss improved from 0.57087 to 0.57052, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5675 - val_loss: 0.5705\n",
      "Epoch 79/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5672\n",
      "Epoch 00079: val_loss did not improve from 0.57052\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5671 - val_loss: 0.5706\n",
      "Epoch 80/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5670\n",
      "Epoch 00080: val_loss improved from 0.57052 to 0.57025, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5669 - val_loss: 0.5703\n",
      "Epoch 81/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5666\n",
      "Epoch 00081: val_loss improved from 0.57025 to 0.57015, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5666 - val_loss: 0.5702\n",
      "Epoch 82/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5666\n",
      "Epoch 00082: val_loss improved from 0.57015 to 0.57005, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5666 - val_loss: 0.5701\n",
      "Epoch 83/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5663\n",
      "Epoch 00083: val_loss improved from 0.57005 to 0.56953, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5663 - val_loss: 0.5695\n",
      "Epoch 84/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5657\n",
      "Epoch 00084: val_loss improved from 0.56953 to 0.56951, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5659 - val_loss: 0.5695\n",
      "Epoch 85/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5657\n",
      "Epoch 00085: val_loss improved from 0.56951 to 0.56920, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5657 - val_loss: 0.5692\n",
      "Epoch 86/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5656\n",
      "Epoch 00086: val_loss did not improve from 0.56920\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5656 - val_loss: 0.5695\n",
      "Epoch 87/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5653\n",
      "Epoch 00087: val_loss did not improve from 0.56920\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5653 - val_loss: 0.5694\n",
      "Epoch 88/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5651\n",
      "Epoch 00088: val_loss improved from 0.56920 to 0.56917, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5651 - val_loss: 0.5692\n",
      "Epoch 89/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5648\n",
      "Epoch 00089: val_loss improved from 0.56917 to 0.56879, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5649 - val_loss: 0.5688\n",
      "Epoch 90/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5648\n",
      "Epoch 00090: val_loss improved from 0.56879 to 0.56854, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5647 - val_loss: 0.5685\n",
      "Epoch 91/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5646\n",
      "Epoch 00091: val_loss improved from 0.56854 to 0.56829, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5646 - val_loss: 0.5683\n",
      "Epoch 92/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5642\n",
      "Epoch 00092: val_loss improved from 0.56829 to 0.56823, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5643 - val_loss: 0.5682\n",
      "Epoch 93/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5643\n",
      "Epoch 00093: val_loss did not improve from 0.56823\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5641 - val_loss: 0.5683\n",
      "Epoch 94/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5640\n",
      "Epoch 00094: val_loss did not improve from 0.56823\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5640 - val_loss: 0.5686\n",
      "Epoch 95/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00095: val_loss improved from 0.56823 to 0.56821, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5637 - val_loss: 0.5682\n",
      "Epoch 96/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.5633\n",
      "Epoch 00096: val_loss improved from 0.56821 to 0.56792, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5634 - val_loss: 0.5679\n",
      "Epoch 97/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5632\n",
      "Epoch 00097: val_loss improved from 0.56792 to 0.56754, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5633 - val_loss: 0.5675\n",
      "Epoch 98/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5631\n",
      "Epoch 00098: val_loss did not improve from 0.56754\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5632 - val_loss: 0.5678\n",
      "Epoch 99/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5629\n",
      "Epoch 00099: val_loss did not improve from 0.56754\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5630 - val_loss: 0.5678\n",
      "Epoch 100/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5627\n",
      "Epoch 00100: val_loss improved from 0.56754 to 0.56717, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5628 - val_loss: 0.5672\n",
      "Epoch 101/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5627\n",
      "Epoch 00101: val_loss did not improve from 0.56717\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5627 - val_loss: 0.5679\n",
      "Epoch 102/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5629\n",
      "Epoch 00102: val_loss improved from 0.56717 to 0.56706, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5627 - val_loss: 0.5671\n",
      "Epoch 103/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5624\n",
      "Epoch 00103: val_loss did not improve from 0.56706\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5624 - val_loss: 0.5673\n",
      "Epoch 104/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5623\n",
      "Epoch 00104: val_loss improved from 0.56706 to 0.56690, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5623 - val_loss: 0.5669\n",
      "Epoch 105/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5622\n",
      "Epoch 00105: val_loss did not improve from 0.56690\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5621 - val_loss: 0.5670\n",
      "Epoch 106/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5621\n",
      "Epoch 00106: val_loss improved from 0.56690 to 0.56671, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5620 - val_loss: 0.5667\n",
      "Epoch 107/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5617\n",
      "Epoch 00107: val_loss improved from 0.56671 to 0.56653, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5618 - val_loss: 0.5665\n",
      "Epoch 108/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5616\n",
      "Epoch 00108: val_loss did not improve from 0.56653\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5616 - val_loss: 0.5666\n",
      "Epoch 109/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5616\n",
      "Epoch 00109: val_loss improved from 0.56653 to 0.56630, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5617 - val_loss: 0.5663\n",
      "Epoch 110/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5613\n",
      "Epoch 00110: val_loss did not improve from 0.56630\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5613 - val_loss: 0.5664\n",
      "Epoch 111/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5614\n",
      "Epoch 00111: val_loss did not improve from 0.56630\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5613 - val_loss: 0.5664\n",
      "Epoch 112/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5609- ETA: 0s - loss: \n",
      "Epoch 00112: val_loss improved from 0.56630 to 0.56617, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5611 - val_loss: 0.5662\n",
      "Epoch 113/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5612\n",
      "Epoch 00113: val_loss improved from 0.56617 to 0.56592, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5611 - val_loss: 0.5659\n",
      "Epoch 114/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5609\n",
      "Epoch 00114: val_loss did not improve from 0.56592\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5610 - val_loss: 0.5660\n",
      "Epoch 115/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5609\n",
      "Epoch 00115: val_loss improved from 0.56592 to 0.56559, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5608 - val_loss: 0.5656\n",
      "Epoch 116/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5607\n",
      "Epoch 00116: val_loss did not improve from 0.56559\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5606 - val_loss: 0.5659\n",
      "Epoch 117/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5607\n",
      "Epoch 00117: val_loss did not improve from 0.56559\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5605 - val_loss: 0.5656\n",
      "Epoch 118/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5604\n",
      "Epoch 00118: val_loss improved from 0.56559 to 0.56551, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5603 - val_loss: 0.5655\n",
      "Epoch 119/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5603\n",
      "Epoch 00119: val_loss improved from 0.56551 to 0.56534, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5603 - val_loss: 0.5653\n",
      "Epoch 120/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5603\n",
      "Epoch 00120: val_loss improved from 0.56534 to 0.56530, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5605 - val_loss: 0.5653\n",
      "Epoch 121/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5600\n",
      "Epoch 00121: val_loss did not improve from 0.56530\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5600 - val_loss: 0.5653\n",
      "Epoch 122/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5601\n",
      "Epoch 00122: val_loss did not improve from 0.56530\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5600 - val_loss: 0.5654\n",
      "Epoch 123/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5598\n",
      "Epoch 00123: val_loss improved from 0.56530 to 0.56530, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5598 - val_loss: 0.5653\n",
      "Epoch 124/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5597\n",
      "Epoch 00124: val_loss did not improve from 0.56530\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5597 - val_loss: 0.5656\n",
      "Epoch 125/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5596\n",
      "Epoch 00125: val_loss did not improve from 0.56530\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5595 - val_loss: 0.5653\n",
      "Epoch 126/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5595\n",
      "Epoch 00126: val_loss improved from 0.56530 to 0.56495, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5595 - val_loss: 0.5649\n",
      "Epoch 127/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5594\n",
      "Epoch 00127: val_loss did not improve from 0.56495\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5594 - val_loss: 0.5651\n",
      "Epoch 128/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5591\n",
      "Epoch 00128: val_loss did not improve from 0.56495\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5592 - val_loss: 0.5651\n",
      "Epoch 129/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.5593\n",
      "Epoch 00129: val_loss did not improve from 0.56495\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5592 - val_loss: 0.5650\n",
      "Epoch 130/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5589\n",
      "Epoch 00130: val_loss improved from 0.56495 to 0.56489, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5590 - val_loss: 0.5649\n",
      "Epoch 131/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5588\n",
      "Epoch 00131: val_loss improved from 0.56489 to 0.56464, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5589 - val_loss: 0.5646\n",
      "Epoch 132/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5590\n",
      "Epoch 00132: val_loss did not improve from 0.56464\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5589 - val_loss: 0.5653\n",
      "Epoch 133/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5587\n",
      "Epoch 00133: val_loss did not improve from 0.56464\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5587 - val_loss: 0.5648\n",
      "Epoch 134/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5589\n",
      "Epoch 00134: val_loss improved from 0.56464 to 0.56453, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5589 - val_loss: 0.5645\n",
      "Epoch 135/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5586\n",
      "Epoch 00135: val_loss improved from 0.56453 to 0.56436, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5586 - val_loss: 0.5644\n",
      "Epoch 136/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5586\n",
      "Epoch 00136: val_loss did not improve from 0.56436\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5584 - val_loss: 0.5658\n",
      "Epoch 137/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5584\n",
      "Epoch 00137: val_loss did not improve from 0.56436\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5583 - val_loss: 0.5644\n",
      "Epoch 138/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5582\n",
      "Epoch 00138: val_loss did not improve from 0.56436\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5582 - val_loss: 0.5650\n",
      "Epoch 139/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5580\n",
      "Epoch 00139: val_loss improved from 0.56436 to 0.56426, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5581 - val_loss: 0.5643\n",
      "Epoch 140/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5583\n",
      "Epoch 00140: val_loss did not improve from 0.56426\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5581 - val_loss: 0.5643\n",
      "Epoch 141/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5579\n",
      "Epoch 00141: val_loss did not improve from 0.56426\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5580 - val_loss: 0.5644\n",
      "Epoch 142/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5579\n",
      "Epoch 00142: val_loss did not improve from 0.56426\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5580 - val_loss: 0.5645\n",
      "Epoch 143/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5578\n",
      "Epoch 00143: val_loss did not improve from 0.56426\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5578 - val_loss: 0.5646\n",
      "Epoch 144/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5576\n",
      "Epoch 00144: val_loss improved from 0.56426 to 0.56423, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5577 - val_loss: 0.5642\n",
      "Epoch 145/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5578\n",
      "Epoch 00145: val_loss did not improve from 0.56423\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5577 - val_loss: 0.5643\n",
      "Epoch 146/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5576\n",
      "Epoch 00146: val_loss improved from 0.56423 to 0.56392, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5575 - val_loss: 0.5639\n",
      "Epoch 147/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5576\n",
      "Epoch 00147: val_loss did not improve from 0.56392\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5574 - val_loss: 0.5646\n",
      "Epoch 148/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5574\n",
      "Epoch 00148: val_loss did not improve from 0.56392\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5574 - val_loss: 0.5641\n",
      "Epoch 149/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5570\n",
      "Epoch 00149: val_loss improved from 0.56392 to 0.56382, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5572 - val_loss: 0.5638\n",
      "Epoch 150/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5575\n",
      "Epoch 00150: val_loss did not improve from 0.56382\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5574 - val_loss: 0.5638\n",
      "Epoch 151/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5572\n",
      "Epoch 00151: val_loss did not improve from 0.56382\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5572 - val_loss: 0.5642\n",
      "Epoch 152/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5569\n",
      "Epoch 00152: val_loss improved from 0.56382 to 0.56376, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5570 - val_loss: 0.5638\n",
      "Epoch 153/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5571\n",
      "Epoch 00153: val_loss did not improve from 0.56376\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5571 - val_loss: 0.5638\n",
      "Epoch 154/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5569\n",
      "Epoch 00154: val_loss did not improve from 0.56376\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5569 - val_loss: 0.5645\n",
      "Epoch 155/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5568\n",
      "Epoch 00155: val_loss did not improve from 0.56376\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5569 - val_loss: 0.5638\n",
      "Epoch 156/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5569\n",
      "Epoch 00156: val_loss improved from 0.56376 to 0.56368, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5569 - val_loss: 0.5637\n",
      "Epoch 157/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5565\n",
      "Epoch 00157: val_loss did not improve from 0.56368\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5566 - val_loss: 0.5638\n",
      "Epoch 158/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5565\n",
      "Epoch 00158: val_loss improved from 0.56368 to 0.56353, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5565 - val_loss: 0.5635\n",
      "Epoch 159/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5564\n",
      "Epoch 00159: val_loss did not improve from 0.56353\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5565 - val_loss: 0.5636\n",
      "Epoch 160/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5565\n",
      "Epoch 00160: val_loss did not improve from 0.56353\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5564 - val_loss: 0.5641\n",
      "Epoch 161/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5563\n",
      "Epoch 00161: val_loss did not improve from 0.56353\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5563 - val_loss: 0.5637\n",
      "Epoch 162/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5564\n",
      "Epoch 00162: val_loss did not improve from 0.56353\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5563 - val_loss: 0.5636\n",
      "Epoch 163/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/149 [============================>.] - ETA: 0s - loss: 0.5563\n",
      "Epoch 00163: val_loss did not improve from 0.56353\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5563 - val_loss: 0.5636\n",
      "Epoch 164/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5563\n",
      "Epoch 00164: val_loss did not improve from 0.56353\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5562 - val_loss: 0.5635\n",
      "Epoch 165/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5559\n",
      "Epoch 00165: val_loss improved from 0.56353 to 0.56350, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5560 - val_loss: 0.5635\n",
      "Epoch 166/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5560\n",
      "Epoch 00166: val_loss did not improve from 0.56350\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5561 - val_loss: 0.5638\n",
      "Epoch 167/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5560\n",
      "Epoch 00167: val_loss improved from 0.56350 to 0.56344, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5560 - val_loss: 0.5634\n",
      "Epoch 168/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5559\n",
      "Epoch 00168: val_loss improved from 0.56344 to 0.56309, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5559 - val_loss: 0.5631\n",
      "Epoch 169/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5557\n",
      "Epoch 00169: val_loss did not improve from 0.56309\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5558 - val_loss: 0.5633\n",
      "Epoch 170/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5556\n",
      "Epoch 00170: val_loss did not improve from 0.56309\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5557 - val_loss: 0.5639\n",
      "Epoch 171/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5557- ETA: 0s - lo\n",
      "Epoch 00171: val_loss did not improve from 0.56309\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5557 - val_loss: 0.5632\n",
      "Epoch 172/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5557\n",
      "Epoch 00172: val_loss did not improve from 0.56309\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5556 - val_loss: 0.5632\n",
      "Epoch 173/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5556\n",
      "Epoch 00173: val_loss did not improve from 0.56309\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5555 - val_loss: 0.5631\n",
      "Epoch 174/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5554\n",
      "Epoch 00174: val_loss did not improve from 0.56309\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5555 - val_loss: 0.5636\n",
      "Epoch 175/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5556\n",
      "Epoch 00175: val_loss improved from 0.56309 to 0.56307, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5553 - val_loss: 0.5631\n",
      "Epoch 176/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5553\n",
      "Epoch 00176: val_loss did not improve from 0.56307\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5553 - val_loss: 0.5634\n",
      "Epoch 177/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5553\n",
      "Epoch 00177: val_loss did not improve from 0.56307\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5552 - val_loss: 0.5635\n",
      "Epoch 178/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5554\n",
      "Epoch 00178: val_loss did not improve from 0.56307\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5551 - val_loss: 0.5633\n",
      "Epoch 179/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5550- ETA\n",
      "Epoch 00179: val_loss improved from 0.56307 to 0.56302, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5550 - val_loss: 0.5630\n",
      "Epoch 180/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5550\n",
      "Epoch 00180: val_loss did not improve from 0.56302\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5551 - val_loss: 0.5631\n",
      "Epoch 181/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5549\n",
      "Epoch 00181: val_loss did not improve from 0.56302\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5550 - val_loss: 0.5635\n",
      "Epoch 182/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5553\n",
      "Epoch 00182: val_loss improved from 0.56302 to 0.56297, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5549 - val_loss: 0.5630\n",
      "Epoch 183/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5548\n",
      "Epoch 00183: val_loss improved from 0.56297 to 0.56289, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5550 - val_loss: 0.5629\n",
      "Epoch 184/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5546\n",
      "Epoch 00184: val_loss did not improve from 0.56289\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5547 - val_loss: 0.5630\n",
      "Epoch 185/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5547\n",
      "Epoch 00185: val_loss did not improve from 0.56289\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5547 - val_loss: 0.5631\n",
      "Epoch 186/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5545\n",
      "Epoch 00186: val_loss improved from 0.56289 to 0.56273, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5546 - val_loss: 0.5627\n",
      "Epoch 187/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5545\n",
      "Epoch 00187: val_loss did not improve from 0.56273\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5546 - val_loss: 0.5627\n",
      "Epoch 188/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5544\n",
      "Epoch 00188: val_loss did not improve from 0.56273\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5545 - val_loss: 0.5629\n",
      "Epoch 189/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5546\n",
      "Epoch 00189: val_loss improved from 0.56273 to 0.56262, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5546 - val_loss: 0.5626\n",
      "Epoch 190/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5544\n",
      "Epoch 00190: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5545 - val_loss: 0.5628\n",
      "Epoch 191/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5542\n",
      "Epoch 00191: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5543 - val_loss: 0.5627\n",
      "Epoch 192/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5545\n",
      "Epoch 00192: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5545 - val_loss: 0.5628\n",
      "Epoch 193/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5541\n",
      "Epoch 00193: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5542 - val_loss: 0.5629\n",
      "Epoch 194/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5542\n",
      "Epoch 00194: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5541 - val_loss: 0.5629\n",
      "Epoch 195/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5540\n",
      "Epoch 00195: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5540 - val_loss: 0.5629\n",
      "Epoch 196/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5538\n",
      "Epoch 00196: val_loss did not improve from 0.56262\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5540 - val_loss: 0.5628\n",
      "Epoch 197/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5540\n",
      "Epoch 00197: val_loss improved from 0.56262 to 0.56240, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5540 - val_loss: 0.5624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5541\n",
      "Epoch 00198: val_loss did not improve from 0.56240\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5540 - val_loss: 0.5639\n",
      "Epoch 199/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5540\n",
      "Epoch 00199: val_loss did not improve from 0.56240\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5539 - val_loss: 0.5626\n",
      "Epoch 200/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5538\n",
      "Epoch 00200: val_loss did not improve from 0.56240\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5537 - val_loss: 0.5630\n",
      "Epoch 201/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5535\n",
      "Epoch 00201: val_loss did not improve from 0.56240\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5536 - val_loss: 0.5626\n",
      "Epoch 202/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5536\n",
      "Epoch 00202: val_loss improved from 0.56240 to 0.56238, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5537 - val_loss: 0.5624\n",
      "Epoch 203/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5536\n",
      "Epoch 00203: val_loss did not improve from 0.56238\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5537 - val_loss: 0.5626\n",
      "Epoch 204/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5536\n",
      "Epoch 00204: val_loss did not improve from 0.56238\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5536 - val_loss: 0.5625\n",
      "Epoch 205/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5534\n",
      "Epoch 00205: val_loss did not improve from 0.56238\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5536 - val_loss: 0.5625\n",
      "Epoch 206/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5534\n",
      "Epoch 00206: val_loss did not improve from 0.56238\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5534 - val_loss: 0.5625\n",
      "Epoch 207/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5535\n",
      "Epoch 00207: val_loss did not improve from 0.56238\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5534 - val_loss: 0.5626\n",
      "Epoch 208/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5535\n",
      "Epoch 00208: val_loss did not improve from 0.56238\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5533 - val_loss: 0.5626\n",
      "Epoch 209/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5533\n",
      "Epoch 00209: val_loss improved from 0.56238 to 0.56222, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5532 - val_loss: 0.5622\n",
      "Epoch 210/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5532\n",
      "Epoch 00210: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5532 - val_loss: 0.5625\n",
      "Epoch 211/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5530\n",
      "Epoch 00211: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5531 - val_loss: 0.5624\n",
      "Epoch 212/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5532\n",
      "Epoch 00212: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5532 - val_loss: 0.5633\n",
      "Epoch 213/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5530\n",
      "Epoch 00213: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5530 - val_loss: 0.5626\n",
      "Epoch 214/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5528\n",
      "Epoch 00214: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5529 - val_loss: 0.5626\n",
      "Epoch 215/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5528\n",
      "Epoch 00215: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5529 - val_loss: 0.5625\n",
      "Epoch 216/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5529\n",
      "Epoch 00216: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5529 - val_loss: 0.5624\n",
      "Epoch 217/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5531\n",
      "Epoch 00217: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5529 - val_loss: 0.5623\n",
      "Epoch 218/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5530\n",
      "Epoch 00218: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5530 - val_loss: 0.5624\n",
      "Epoch 219/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5526\n",
      "Epoch 00219: val_loss did not improve from 0.56222\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5526 - val_loss: 0.5623\n",
      "Epoch 220/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5525\n",
      "Epoch 00220: val_loss improved from 0.56222 to 0.56214, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5526 - val_loss: 0.5621\n",
      "Epoch 221/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5524\n",
      "Epoch 00221: val_loss did not improve from 0.56214\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5525 - val_loss: 0.5624\n",
      "Epoch 222/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5528\n",
      "Epoch 00222: val_loss did not improve from 0.56214\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5526 - val_loss: 0.5626\n",
      "Epoch 223/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5526\n",
      "Epoch 00223: val_loss did not improve from 0.56214\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5526 - val_loss: 0.5623\n",
      "Epoch 224/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5524\n",
      "Epoch 00224: val_loss improved from 0.56214 to 0.56211, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5525 - val_loss: 0.5621\n",
      "Epoch 225/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5523\n",
      "Epoch 00225: val_loss did not improve from 0.56211\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5523 - val_loss: 0.5622\n",
      "Epoch 226/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5521\n",
      "Epoch 00226: val_loss did not improve from 0.56211\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5523 - val_loss: 0.5631\n",
      "Epoch 227/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5525\n",
      "Epoch 00227: val_loss did not improve from 0.56211\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5523 - val_loss: 0.5622\n",
      "Epoch 228/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5521\n",
      "Epoch 00228: val_loss did not improve from 0.56211\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5522 - val_loss: 0.5632\n",
      "Epoch 229/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5522\n",
      "Epoch 00229: val_loss did not improve from 0.56211\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5522 - val_loss: 0.5624\n",
      "Epoch 230/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5521\n",
      "Epoch 00230: val_loss improved from 0.56211 to 0.56196, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5523 - val_loss: 0.5620\n",
      "Epoch 231/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5519\n",
      "Epoch 00231: val_loss did not improve from 0.56196\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5521 - val_loss: 0.5620\n",
      "Epoch 232/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5521\n",
      "Epoch 00232: val_loss did not improve from 0.56196\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5521 - val_loss: 0.5624\n",
      "Epoch 233/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5520\n",
      "Epoch 00233: val_loss did not improve from 0.56196\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5520 - val_loss: 0.5621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5521\n",
      "Epoch 00234: val_loss improved from 0.56196 to 0.56190, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5519 - val_loss: 0.5619\n",
      "Epoch 235/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5520\n",
      "Epoch 00235: val_loss did not improve from 0.56190\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5519 - val_loss: 0.5620\n",
      "Epoch 236/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5519\n",
      "Epoch 00236: val_loss did not improve from 0.56190\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5517 - val_loss: 0.5620\n",
      "Epoch 237/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5517\n",
      "Epoch 00237: val_loss did not improve from 0.56190\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5518 - val_loss: 0.5622\n",
      "Epoch 238/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5518\n",
      "Epoch 00238: val_loss did not improve from 0.56190\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5518 - val_loss: 0.5619\n",
      "Epoch 239/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5517\n",
      "Epoch 00239: val_loss did not improve from 0.56190\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5517 - val_loss: 0.5621\n",
      "Epoch 240/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5516\n",
      "Epoch 00240: val_loss did not improve from 0.56190\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5516 - val_loss: 0.5619\n",
      "Epoch 241/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5515\n",
      "Epoch 00241: val_loss improved from 0.56190 to 0.56189, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5516 - val_loss: 0.5619\n",
      "Epoch 242/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5514\n",
      "Epoch 00242: val_loss improved from 0.56189 to 0.56174, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5515 - val_loss: 0.5617\n",
      "Epoch 243/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5517\n",
      "Epoch 00243: val_loss did not improve from 0.56174\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5515 - val_loss: 0.5625\n",
      "Epoch 244/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5515\n",
      "Epoch 00244: val_loss did not improve from 0.56174\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5514 - val_loss: 0.5620\n",
      "Epoch 245/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5515\n",
      "Epoch 00245: val_loss did not improve from 0.56174\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5514 - val_loss: 0.5619\n",
      "Epoch 246/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5512\n",
      "Epoch 00246: val_loss did not improve from 0.56174\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5512 - val_loss: 0.5623\n",
      "Epoch 247/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5515\n",
      "Epoch 00247: val_loss improved from 0.56174 to 0.56171, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5513 - val_loss: 0.5617\n",
      "Epoch 248/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5513\n",
      "Epoch 00248: val_loss improved from 0.56171 to 0.56168, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5513 - val_loss: 0.5617\n",
      "Epoch 249/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5513\n",
      "Epoch 00249: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5514 - val_loss: 0.5617\n",
      "Epoch 250/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5511\n",
      "Epoch 00250: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5511 - val_loss: 0.5629\n",
      "Epoch 251/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5512\n",
      "Epoch 00251: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5513 - val_loss: 0.5620\n",
      "Epoch 252/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5511\n",
      "Epoch 00252: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5510 - val_loss: 0.5619\n",
      "Epoch 253/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5514\n",
      "Epoch 00253: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5511 - val_loss: 0.5620\n",
      "Epoch 254/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5508\n",
      "Epoch 00254: val_loss improved from 0.56168 to 0.56168, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5510 - val_loss: 0.5617\n",
      "Epoch 255/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5510\n",
      "Epoch 00255: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5510 - val_loss: 0.5618\n",
      "Epoch 256/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5508\n",
      "Epoch 00256: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5509 - val_loss: 0.5619\n",
      "Epoch 257/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5510\n",
      "Epoch 00257: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5510 - val_loss: 0.5618\n",
      "Epoch 258/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5506\n",
      "Epoch 00258: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5507 - val_loss: 0.5618\n",
      "Epoch 259/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5507\n",
      "Epoch 00259: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5508 - val_loss: 0.5620\n",
      "Epoch 260/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5506\n",
      "Epoch 00260: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5507 - val_loss: 0.5620\n",
      "Epoch 261/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5505\n",
      "Epoch 00261: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5506 - val_loss: 0.5617\n",
      "Epoch 262/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5506\n",
      "Epoch 00262: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5506 - val_loss: 0.5621\n",
      "Epoch 263/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5504\n",
      "Epoch 00263: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5506 - val_loss: 0.5624\n",
      "Epoch 264/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5505\n",
      "Epoch 00264: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5506 - val_loss: 0.5618\n",
      "Epoch 265/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5507\n",
      "Epoch 00265: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5505 - val_loss: 0.5618\n",
      "Epoch 266/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5506- ETA: 0s - los\n",
      "Epoch 00266: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5505 - val_loss: 0.5619\n",
      "Epoch 267/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5503\n",
      "Epoch 00267: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5504 - val_loss: 0.5617\n",
      "Epoch 268/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5503\n",
      "Epoch 00268: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5502 - val_loss: 0.5620\n",
      "Epoch 269/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5503\n",
      "Epoch 00269: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5504 - val_loss: 0.5621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5502\n",
      "Epoch 00270: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5502 - val_loss: 0.5617\n",
      "Epoch 271/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5502\n",
      "Epoch 00271: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5502 - val_loss: 0.5617\n",
      "Epoch 272/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5503\n",
      "Epoch 00272: val_loss did not improve from 0.56168\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5503 - val_loss: 0.5625\n",
      "Epoch 273/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5500\n",
      "Epoch 00273: val_loss improved from 0.56168 to 0.56151, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5501 - val_loss: 0.5615\n",
      "Epoch 274/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5501\n",
      "Epoch 00274: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5501 - val_loss: 0.5619\n",
      "Epoch 275/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5499\n",
      "Epoch 00275: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5500 - val_loss: 0.5616\n",
      "Epoch 276/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5501\n",
      "Epoch 00276: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5501 - val_loss: 0.5618\n",
      "Epoch 277/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5497\n",
      "Epoch 00277: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5498 - val_loss: 0.5617\n",
      "Epoch 278/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5498\n",
      "Epoch 00278: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5499 - val_loss: 0.5617\n",
      "Epoch 279/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5497\n",
      "Epoch 00279: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5498 - val_loss: 0.5619\n",
      "Epoch 280/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5498\n",
      "Epoch 00280: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5498 - val_loss: 0.5619\n",
      "Epoch 281/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5497\n",
      "Epoch 00281: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5498 - val_loss: 0.5618\n",
      "Epoch 282/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5496\n",
      "Epoch 00282: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5497 - val_loss: 0.5618\n",
      "Epoch 283/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5497\n",
      "Epoch 00283: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5497 - val_loss: 0.5619\n",
      "Epoch 284/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5496\n",
      "Epoch 00284: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5496 - val_loss: 0.5618\n",
      "Epoch 285/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5495\n",
      "Epoch 00285: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5496 - val_loss: 0.5617\n",
      "Epoch 286/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5494\n",
      "Epoch 00286: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5495 - val_loss: 0.5617\n",
      "Epoch 287/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5498\n",
      "Epoch 00287: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5496 - val_loss: 0.5617\n",
      "Epoch 288/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5495\n",
      "Epoch 00288: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 81ms/step - loss: 0.5495 - val_loss: 0.5617\n",
      "Epoch 289/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5497\n",
      "Epoch 00289: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 13s 84ms/step - loss: 0.5494 - val_loss: 0.5616\n",
      "Epoch 290/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5495\n",
      "Epoch 00290: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5494 - val_loss: 0.5618\n",
      "Epoch 291/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5495\n",
      "Epoch 00291: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5494 - val_loss: 0.5618\n",
      "Epoch 292/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5494\n",
      "Epoch 00292: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5493 - val_loss: 0.5618\n",
      "Epoch 293/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5492\n",
      "Epoch 00293: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5493 - val_loss: 0.5622\n",
      "Epoch 294/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5492\n",
      "Epoch 00294: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5492 - val_loss: 0.5621\n",
      "Epoch 295/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5490\n",
      "Epoch 00295: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5491 - val_loss: 0.5619\n",
      "Epoch 296/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5490\n",
      "Epoch 00296: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5491 - val_loss: 0.5616\n",
      "Epoch 297/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5490\n",
      "Epoch 00297: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5490 - val_loss: 0.5617\n",
      "Epoch 298/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5489- ETA: 0s - loss: 0.54\n",
      "Epoch 00298: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5489 - val_loss: 0.5620\n",
      "Epoch 299/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5491\n",
      "Epoch 00299: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5491 - val_loss: 0.5618\n",
      "Epoch 300/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5490\n",
      "Epoch 00300: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5490 - val_loss: 0.5617\n",
      "Epoch 301/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5489\n",
      "Epoch 00301: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5489 - val_loss: 0.5617\n",
      "Epoch 302/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5489\n",
      "Epoch 00302: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5489 - val_loss: 0.5617\n",
      "Epoch 303/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5489\n",
      "Epoch 00303: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5489 - val_loss: 0.5619\n",
      "Epoch 304/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5487\n",
      "Epoch 00304: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5488 - val_loss: 0.5618\n",
      "Epoch 305/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5489\n",
      "Epoch 00305: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5489 - val_loss: 0.5619\n",
      "Epoch 306/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5487\n",
      "Epoch 00306: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5488 - val_loss: 0.5617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5487\n",
      "Epoch 00307: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5487 - val_loss: 0.5619\n",
      "Epoch 308/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 00308: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5487 - val_loss: 0.5628\n",
      "Epoch 309/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 00309: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5485 - val_loss: 0.5620\n",
      "Epoch 310/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 00310: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5485 - val_loss: 0.5616\n",
      "Epoch 311/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5484- ETA: 0s - l\n",
      "Epoch 00311: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5485 - val_loss: 0.5616\n",
      "Epoch 312/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 00312: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5485 - val_loss: 0.5617\n",
      "Epoch 313/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5484\n",
      "Epoch 00313: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 13s 85ms/step - loss: 0.5484 - val_loss: 0.5619\n",
      "Epoch 314/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5485\n",
      "Epoch 00314: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 84ms/step - loss: 0.5483 - val_loss: 0.5621\n",
      "Epoch 315/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5482\n",
      "Epoch 00315: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5483 - val_loss: 0.5617\n",
      "Epoch 316/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5484\n",
      "Epoch 00316: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5483 - val_loss: 0.5617\n",
      "Epoch 317/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5482\n",
      "Epoch 00317: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5483 - val_loss: 0.5618\n",
      "Epoch 318/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5483\n",
      "Epoch 00318: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5483 - val_loss: 0.5622\n",
      "Epoch 319/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5484\n",
      "Epoch 00319: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5483 - val_loss: 0.5620\n",
      "Epoch 320/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5481\n",
      "Epoch 00320: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5482 - val_loss: 0.5616\n",
      "Epoch 321/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5482\n",
      "Epoch 00321: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5481 - val_loss: 0.5625\n",
      "Epoch 322/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5482\n",
      "Epoch 00322: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5481 - val_loss: 0.5617\n",
      "Epoch 323/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5480\n",
      "Epoch 00323: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5480 - val_loss: 0.5617\n",
      "Epoch 324/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5483\n",
      "Epoch 00324: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5481 - val_loss: 0.5619\n",
      "Epoch 325/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5480\n",
      "Epoch 00325: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5479 - val_loss: 0.5623\n",
      "Epoch 326/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5480\n",
      "Epoch 00326: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5479 - val_loss: 0.5621\n",
      "Epoch 327/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5480\n",
      "Epoch 00327: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5478 - val_loss: 0.5617\n",
      "Epoch 328/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5478\n",
      "Epoch 00328: val_loss improved from 0.56151 to 0.56151, saving model to insectWing_dimension_16.h5\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5479 - val_loss: 0.5615\n",
      "Epoch 329/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5479\n",
      "Epoch 00329: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5477 - val_loss: 0.5619\n",
      "Epoch 330/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5478\n",
      "Epoch 00330: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5478 - val_loss: 0.5619\n",
      "Epoch 331/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5478\n",
      "Epoch 00331: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5477 - val_loss: 0.5619\n",
      "Epoch 332/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5482\n",
      "Epoch 00332: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5477 - val_loss: 0.5618\n",
      "Epoch 333/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5477\n",
      "Epoch 00333: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5477 - val_loss: 0.5625\n",
      "Epoch 334/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5475\n",
      "Epoch 00334: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5475 - val_loss: 0.5618\n",
      "Epoch 335/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5475\n",
      "Epoch 00335: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5476 - val_loss: 0.5617\n",
      "Epoch 336/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 00336: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5475 - val_loss: 0.5622\n",
      "Epoch 337/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 00337: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5475 - val_loss: 0.5619\n",
      "Epoch 338/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5475\n",
      "Epoch 00338: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5475 - val_loss: 0.5620\n",
      "Epoch 339/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5475\n",
      "Epoch 00339: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5474 - val_loss: 0.5619\n",
      "Epoch 340/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5473\n",
      "Epoch 00340: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5474 - val_loss: 0.5619\n",
      "Epoch 341/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5477\n",
      "Epoch 00341: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5474 - val_loss: 0.5621\n",
      "Epoch 342/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 00342: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5473 - val_loss: 0.5619\n",
      "Epoch 343/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5471\n",
      "Epoch 00343: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5472 - val_loss: 0.5619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 00344: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 83ms/step - loss: 0.5472 - val_loss: 0.5621\n",
      "Epoch 345/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5474\n",
      "Epoch 00345: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5472 - val_loss: 0.5626\n",
      "Epoch 346/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5473\n",
      "Epoch 00346: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5472 - val_loss: 0.5625\n",
      "Epoch 347/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5473\n",
      "Epoch 00347: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5472 - val_loss: 0.5619\n",
      "Epoch 348/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5472\n",
      "Epoch 00348: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5472 - val_loss: 0.5620\n",
      "Epoch 349/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5470\n",
      "Epoch 00349: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5471 - val_loss: 0.5620\n",
      "Epoch 350/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5470\n",
      "Epoch 00350: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5470 - val_loss: 0.5624\n",
      "Epoch 351/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5469\n",
      "Epoch 00351: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5470 - val_loss: 0.5622\n",
      "Epoch 352/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5471\n",
      "Epoch 00352: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5469 - val_loss: 0.5618\n",
      "Epoch 353/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5469\n",
      "Epoch 00353: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5468 - val_loss: 0.5618\n",
      "Epoch 354/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5471\n",
      "Epoch 00354: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5469 - val_loss: 0.5619\n",
      "Epoch 355/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5467\n",
      "Epoch 00355: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5468 - val_loss: 0.5622\n",
      "Epoch 356/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "Epoch 00356: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5467 - val_loss: 0.5620\n",
      "Epoch 357/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5468\n",
      "Epoch 00357: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5468 - val_loss: 0.5621\n",
      "Epoch 358/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5467\n",
      "Epoch 00358: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5468 - val_loss: 0.5618\n",
      "Epoch 359/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5465\n",
      "Epoch 00359: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5466 - val_loss: 0.5619\n",
      "Epoch 360/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5468\n",
      "Epoch 00360: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5467 - val_loss: 0.5619\n",
      "Epoch 361/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "Epoch 00361: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5466 - val_loss: 0.5623\n",
      "Epoch 362/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5465\n",
      "Epoch 00362: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5465 - val_loss: 0.5623\n",
      "Epoch 363/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5465\n",
      "Epoch 00363: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5467 - val_loss: 0.5623\n",
      "Epoch 364/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5465\n",
      "Epoch 00364: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5465 - val_loss: 0.5622\n",
      "Epoch 365/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5464\n",
      "Epoch 00365: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5465 - val_loss: 0.5624\n",
      "Epoch 366/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5464\n",
      "Epoch 00366: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5465 - val_loss: 0.5619\n",
      "Epoch 367/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "Epoch 00367: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5464 - val_loss: 0.5619\n",
      "Epoch 368/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5466\n",
      "Epoch 00368: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5464 - val_loss: 0.5622\n",
      "Epoch 369/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5463\n",
      "Epoch 00369: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5463 - val_loss: 0.5623\n",
      "Epoch 370/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5464\n",
      "Epoch 00370: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5463 - val_loss: 0.5620\n",
      "Epoch 371/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5461\n",
      "Epoch 00371: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5461 - val_loss: 0.5630\n",
      "Epoch 372/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5461\n",
      "Epoch 00372: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5462 - val_loss: 0.5621\n",
      "Epoch 373/5000\n",
      "148/149 [============================>.] - ETA: 0s - loss: 0.5462\n",
      "Epoch 00373: val_loss did not improve from 0.56151\n",
      "149/149 [==============================] - 12s 82ms/step - loss: 0.5462 - val_loss: 0.5619\n",
      "Epoch 00373: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.train(X_train,batch_size,epochs,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "# loss_ax.plot([hist['loss'][i] - hist['val_loss'][i] for i in range(len(hist['loss']))], 'g', label='loss - val loss')\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1980,256,256,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-28e3310333b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\문서\\GitHub\\Sanhak-Lab\\논문실험\\agent.py\u001b[0m in \u001b[0;36mfeature_extract\u001b[1;34m(self, X_data)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeature_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mget_5th_layer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompressed_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mcompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_5th_layer_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mcompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompressed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompressed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompressed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcompressed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcompressed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcompressed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mfunc\u001b[1;34m(model_inputs)\u001b[0m\n\u001b[0;32m   3938\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3940\u001b[1;33m       \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3941\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mwrap_outputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3942\u001b[0m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[0;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 386\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1016\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1018\u001b[1;33m       name=name)\n\u001b[0m\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1146\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m           name=name)\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2590\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2593\u001b[0m   return squeeze_batch_dims(\n\u001b[0;32m   2594\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    936\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shims\\anaconda3\\envs\\foodflask\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1980,256,256,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "feature = autoencoder.feature_extract(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 16)\n"
     ]
    }
   ],
   "source": [
    "features = np.empty((0,16), float)\n",
    "for i in range(66):\n",
    "    features = np.append(features, autoencoder.feature_extract(X_scaled[i*30:(i+1)*30]), axis=0)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10733952139479039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Cluster Algorithm\n",
    "result = KMeans(n_clusters=11).fit(features)\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score\n",
    "\n",
    "def plotSilhouette(X, y_km):\n",
    "    cluster_labels = np.unique(y_km.labels_)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = silhouette_score(X, y_km.labels_,metric='euclidean')\n",
    "    print(silhouette_vals)\n",
    "    \n",
    "plotSilhouette(features,result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11579906138338754\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import save_model\n",
    "autoencoder.model.save_weights(\"insectWing_binary_16_128_0.5885.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
